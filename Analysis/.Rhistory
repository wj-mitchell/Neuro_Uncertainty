df_ <- df_[(1 + 45 + 9):(nrow(df_) - 45),]
}
# If the participant's file has 729 datapoints
if (nrow(df_) == 729){
# Create an onset sequence that removes the first 60 and last 60 seconds, plus the 17 second buffer
df_ <- df_[(1 + 30 + 9):(nrow(df_) - 30),]
}
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- cbind(df, df_)
}
}
## Cleaning the space
rm(Run, PID, files, FILE, df_)
Window_Sizes <- c(30,40,50)
WINDOW <- Window_Sizes[2]
nROI <- 400
registerDoMC(detectCores()/2)
rows <- 1:(nrow(df) - (WINDOW/2))
cols <- c("PID1", "PID2", "Run", "Region", "Window", "Value_Cor_Neuro")
df_model <- as.data.frame(matrix(NA,
nrow = length(rows),
ncol = length(cols),
dimnames = list(rows, cols)))
rm(rows,cols)
## Iterating through each run
foreach(RUN=1:1)  %:%
## and iterating through each of the ROIs
foreach(ROI=1:2) %dopar% {
## Identifying the Data that is Comparable to Correlate
df_cor_ <- grep(pattern = paste0("run-", RUN, "_ROI-", ROI, "$"),
x = names(df),
value = TRUE) %>%
df[,.]
## Iterating through the Different Combinations
for (PID1 in 1:(ncol(df_cor_) - 1)){
for (PID2 in 2:ncol(df_cor_)){
if (PID2 > PID1){
# Creating a new dataframe with the structure of df_cor
df_temp <- df_model
# Filling in information
df_temp$PID1 <- sub("(_run-.*)", "", names(df_cor_)[PID1])
df_temp$PID2 <- sub("(_run-.*)", "", names(df_cor_)[PID2])
df_temp$Run <- RUN
df_temp$Region <- ROI
df_temp$Window <- 1:nrow(df_temp)
df_temp$Value_Cor_Neuro <- Sliding_Window_Cor(x = df_cor_[,PID1],
y = df_cor_[,PID2],
window_size = WINDOW)
## If this is the first iteration
if (PID1 == 1 & PID2 == 2){
## Make the generated dataframe the standard
df_cor <- df_temp
}
## If this is a later iteration
if (PID1 != 1 | PID2 != 2){
## Bind the rows together
df_cor <- rbind(df_cor,
df_temp)
}
}
}
# Print Progress
print(paste0("RUN: ", RUN, " | ROI: ", ROI, " | PID1: ", PID1))
}
## Save the current dataframe
write.csv(df_cor,
paste0(here(),"/Data/Sliding_Window/nROI-", nROI,"_WinSize-", WINDOW,"_Run-",RUN,"_ROI-", ROI,".csv"))
}
## Loading Packages
pacman::p_load(doMC,
foreach,
here,
lme4,
lmerTest,
parallel,
tidyverse)
## Adding custom function
source("https://raw.githubusercontent.com/wj-mitchell/neuRotools/main/cormat_long.R", local= T)
source(paste0(here(), "/Analysis/Sliding_Window_Cor.R"), local= T)
files <- list.files(paste0(here(), "/Data/AvgROI/"),
full.names = TRUE)
PIDs <- NULL
## Iterating through each of these files
for (FILE in 1:length(files)){
## Reading in the data for this iteration
df_ <- read.csv(files[FILE])
## Identifying the Participant ID for this file
PID <- sub(".*/sub-(\\d+)_.*", "\\1", files[FILE])
## If the PID isn't present in the PIDs array
if (all(PIDs != PID)){
## add the PID to the array
PIDs <- c(PIDs, PID)
}
## Identifying the Run for this participant
Run <- sub(".*/sub-\\d+_(run-\\d+)_.*", "\\1", files[FILE])
## Renaming the column headers
names(df_) <- paste0("sub-", PID, "_", Run, "_ROI-",1:ncol(df_))
# If the participant's file has 759 datapoints
if (nrow(df_) == 759){
# Create an onset sequence that removes the first 90 and last 90 seconds, plus the 17 second buffer
df_ <- df_[(1 + 45 + 9):(nrow(df_) - 45),]
}
# If the participant's file has 729 datapoints
if (nrow(df_) == 729){
# Create an onset sequence that removes the first 60 and last 60 seconds, plus the 17 second buffer
df_ <- df_[(1 + 30 + 9):(nrow(df_) - 30),]
}
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- cbind(df, df_)
}
}
## Cleaning the space
rm(Run, PID, files, FILE, df_)
Window_Sizes <- c(30,40,50)
nROI <- 400
registerDoMC(detectCores()/2)
## Iterating through differently sized windows
for (WINDOW in Window_Sizes) {
## Creating a model dataframe to reference
rows <- 1:(nrow(df) - (WINDOW/2))
cols <- c("PID1", "PID2", "Run", "Region", "Window", "Value_Cor_Neuro")
df_model <- as.data.frame(matrix(NA,
nrow = length(rows),
ncol = length(cols),
dimnames = list(rows, cols)))
rm(rows,cols)
## Iterating through each run
foreach(RUN=1:1)  %:%
## and iterating through each of the ROIs
foreach(ROI=1:2) %dopar% {
## Identifying the Data that is Comparable to Correlate
df_cor_ <- grep(pattern = paste0("run-", RUN, "_ROI-", ROI, "$"),
x = names(df),
value = TRUE) %>%
df[,.]
## Iterating through the Different Combinations
for (PID1 in 1:(ncol(df_cor_) - 1)){
for (PID2 in 2:ncol(df_cor_)){
if (PID2 > PID1){
# Creating a new dataframe with the structure of df_cor
df_temp <- df_model
# Filling in information
df_temp$PID1 <- sub("(_run-.*)", "", names(df_cor_)[PID1])
df_temp$PID2 <- sub("(_run-.*)", "", names(df_cor_)[PID2])
df_temp$Run <- RUN
df_temp$Region <- ROI
df_temp$Window <- 1:nrow(df_temp)
df_temp$Value_Cor_Neuro <- Sliding_Window_Cor(x = df_cor_[,PID1],
y = df_cor_[,PID2],
window_size = WINDOW)
## If this is the first iteration
if (PID1 == 1 & PID2 == 2){
## Make the generated dataframe the standard
df_cor <- df_temp
}
## If this is a later iteration
if (PID1 != 1 | PID2 != 2){
## Bind the rows together
df_cor <- rbind(df_cor,
df_temp)
}
}
}
# Print Progress
print(paste0("RUN: ", RUN, " | ROI: ", ROI, " | PID1: ", PID1))
}
## Save the current dataframe
write.csv(df_cor,
paste0(here(),"/Data/Sliding_Window/nROI-", nROI,"_WinSize-", WINDOW,"_Run-",RUN,"_ROI-", ROI,".csv"))
}
}
## Loading Packages
pacman::p_load(doMC,
foreach,
here,
lme4,
lmerTest,
parallel,
tidyverse)
## Adding custom function
source("https://raw.githubusercontent.com/wj-mitchell/neuRotools/main/cormat_long.R", local= T)
source(paste0(here(), "/Analysis/Sliding_Window_Cor.R"), local= T)
files <- list.files(paste0(here(), "/Data/AvgROI/"),
full.names = TRUE)
PIDs <- NULL
## Iterating through each of these files
for (FILE in 1:length(files)){
## Reading in the data for this iteration
df_ <- read.csv(files[FILE])
## Identifying the Participant ID for this file
PID <- sub(".*/sub-(\\d+)_.*", "\\1", files[FILE])
## If the PID isn't present in the PIDs array
if (all(PIDs != PID)){
## add the PID to the array
PIDs <- c(PIDs, PID)
}
## Identifying the Run for this participant
Run <- sub(".*/sub-\\d+_(run-\\d+)_.*", "\\1", files[FILE])
## Renaming the column headers
names(df_) <- paste0("sub-", PID, "_", Run, "_ROI-",1:ncol(df_))
# If the participant's file has 759 datapoints
if (nrow(df_) == 759){
# Create an onset sequence that removes the first 90 and last 90 seconds, plus the 17 second buffer
df_ <- df_[(1 + 45 + 9):(nrow(df_) - 45),]
}
# If the participant's file has 729 datapoints
if (nrow(df_) == 729){
# Create an onset sequence that removes the first 60 and last 60 seconds, plus the 17 second buffer
df_ <- df_[(1 + 30 + 9):(nrow(df_) - 30),]
}
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- cbind(df, df_)
}
}
## Cleaning the space
rm(Run, PID, files, FILE, df_)
Window_Sizes <- c(30,40,50)
nROI <- 400
registerDoMC(detectCores()/2)
## Iterating through differently sized windows
for (WINDOW in Window_Sizes) {
## Creating a model dataframe to reference
rows <- 1:(nrow(df) - (WINDOW/2))
cols <- c("PID1", "PID2", "Run", "Region", "Window", "Value_Cor_Neuro")
df_model <- as.data.frame(matrix(NA,
nrow = length(rows),
ncol = length(cols),
dimnames = list(rows, cols)))
rm(rows,cols)
## Iterating through each run
foreach(RUN=1:1)  %:%
## and iterating through each of the ROIs
foreach(ROI=1:2) %dopar% {
## Identifying the Data that is Comparable to Correlate
df_cor_ <- grep(pattern = paste0("run-", RUN, "_ROI-", ROI, "$"),
x = names(df),
value = TRUE) %>%
df[,.]
## Iterating through the Different Combinations
for (PID1 in 1:(ncol(df_cor_) - 1)){
for (PID2 in 2:ncol(df_cor_)){
if (PID2 > PID1){
# Creating a new dataframe with the structure of df_cor
df_temp <- df_model
# Filling in information
df_temp$PID1 <- sub("(_run-.*)", "", names(df_cor_)[PID1])
df_temp$PID2 <- sub("(_run-.*)", "", names(df_cor_)[PID2])
df_temp$Run <- RUN
df_temp$Region <- ROI
df_temp$Window <- 1:nrow(df_temp)
df_temp$Value_Cor_Neuro <- Sliding_Window_Cor(x = df_cor_[,PID1],
y = df_cor_[,PID2],
window_size = WINDOW)
## If this is the first iteration
if (PID1 == 1 & PID2 == 2){
## Make the generated dataframe the standard
df_cor <- df_temp
}
## If this is a later iteration
if (PID1 != 1 | PID2 != 2){
## Bind the rows together
df_cor <- rbind(df_cor,
df_temp)
}
}
}
# Print Progress
# print(paste0("RUN: ", RUN, " | ROI: ", ROI, " | PID1: ", PID1))
}
## Save the current dataframe
write.csv(df_cor,
paste0(here(),"/Data/Sliding_Window/nROI-", nROI,"_WinSize-", WINDOW,"_Run-",RUN,"_ROI-", ROI,".csv"))
}
}
## Iterating through differently sized windows
for (WINDOW in Window_Sizes) {
## Creating a model dataframe to reference
rows <- 1:(nrow(df) - (WINDOW/2))
cols <- c("PID1", "PID2", "Run", "Region", "Window", "Value_Cor_Neuro")
df_model <- as.data.frame(matrix(NA,
nrow = length(rows),
ncol = length(cols),
dimnames = list(rows, cols)))
rm(rows,cols)
## Iterating through each run
foreach(RUN=1:2)  %:%
## and iterating through each of the ROIs
foreach(ROI=1:400) %dopar% {
## Identifying the Data that is Comparable to Correlate
df_cor_ <- grep(pattern = paste0("run-", RUN, "_ROI-", ROI, "$"),
x = names(df),
value = TRUE) %>%
df[,.]
## Iterating through the Different Combinations
for (PID1 in 1:(ncol(df_cor_) - 1)){
for (PID2 in 2:ncol(df_cor_)){
if (PID2 > PID1){
# Creating a new dataframe with the structure of df_cor
df_temp <- df_model
# Filling in information
df_temp$PID1 <- sub("(_run-.*)", "", names(df_cor_)[PID1])
df_temp$PID2 <- sub("(_run-.*)", "", names(df_cor_)[PID2])
df_temp$Run <- RUN
df_temp$Region <- ROI
df_temp$Window <- 1:nrow(df_temp)
df_temp$Value_Cor_Neuro <- Sliding_Window_Cor(x = df_cor_[,PID1],
y = df_cor_[,PID2],
window_size = WINDOW)
## If this is the first iteration
if (PID1 == 1 & PID2 == 2){
## Make the generated dataframe the standard
df_cor <- df_temp
}
## If this is a later iteration
if (PID1 != 1 | PID2 != 2){
## Bind the rows together
df_cor <- rbind(df_cor,
df_temp)
}
}
}
# Print Progress
# print(paste0("RUN: ", RUN, " | ROI: ", ROI, " | PID1: ", PID1))
}
## Save the current dataframe
write.csv(df_cor,
paste0(here(),"/Data/Sliding_Window/nROI-", nROI,"_WinSize-", WINDOW,"_Run-",RUN,"_ROI-", ROI,".csv"))
}
}
setwd("/data/Uncertainty/scripts")
## Loading Packages
pacman::p_load(here,
tidyverse)
files <- list.files(paste0(here(), "/Data/Sliding_Window/Results"),
full.names = TRUE)
## Iterating through each of these files
for (FILE in 1:length(files)){
## Reading in the data for this iteration
df_ <- read.csv(files[FILE],
row.names = 1)
## Identifying the Run for this participant
Window_Size <- sub(".*/.*_(WinSize-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9][0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
Run <- sub(".*/.*_(Run-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
ROI <- sub(".*/.*_(ROI-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9].*$") %>%
as.numeric()
## Adding additional information to the dataframe
df_$Window_Size <- Window_Size
df_$Run <- Run
df_$ROI <- ROI
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- rbind(df, df_)
}
}
## Cleaning the space
rm(Run, Window_Size, ROI, files, FILE, df_)
df <- df %>%
select(c("Window_Size", "Run", "ROI", "Model", "term", "estimate",
"std.error", "statistic", "df", "p.value", "ICC_adj",
"ModelComparison", "Base_npar", "Base_AIC", "Base_BIC",
"Base_logLik", "Base_deviance", "Compare_npar", "Compare_AIC",
"Compare_BIC", "Compare_logLik", "Compare_deviance", "Chisq",
"Df", "Pr..Chisq."))
df_ROI <- read.table(paste0(here(), "/Pre-Processing/dir_ROIs/ROIs_Schaefer.txt"))
for (ROI in 1:nrow(df_ROI)){
df$ROI[df$ROI == ROI] <- df_ROI$V1[ROI]
}
df_results_R1 <- df %>%
subset(.$Window_Size == 50 & .$Run == 1 & .$Model == "M4" & .$term == "Value_Cor_Neuro:MidSimSame")
median(df_results_R1$Pr..Chisq.)
df_results_R1$p.value_adj <- p.adjust(df_results_R1$p.value, method = "bonferroni")
df_results_R1 <- df_results_R1 %>%
subset(.$p.value_adj < 0.001)
df_results_R2 <- df %>%
subset(.$Window_Size == 50 & .$Run == 2 & .$Model == "M6" & .$term == "Value_Cor_Neuro:EndSimSame")
median(df_results_R2$Pr..Chisq.)
df_results_R2$p.value_adj <- p.adjust(df_results_R2$p.value, method = "bonferroni")
df_results_R2 <- df_results_R2 %>%
subset(.$p.value < 0.001)
df_exp <- rbind(df_results_R1,df_results_R2) %>%
select(c("ROI", "estimate", "std.error", "statistic", "df", "p.value_adj")) %>%
group_by(ROI) %>%
summarize(count = n(),
estimate = mean(estimate),
std.error = mean(std.error),
statistic = mean(statistic),
df = mean(df),
p.value_adj = mean(p.value_adj)) %>%
ungroup() %>%
subset(.$count > 1 & .$p.value_adj < 0.001)
View(df_exp)
## Loading Packages
pacman::p_load(here,
tidyverse)
files <- list.files(paste0(here(), "/Data/Sliding_Window/Results"),
full.names = TRUE)
## Iterating through each of these files
for (FILE in 1:length(files)){
## Reading in the data for this iteration
df_ <- read.csv(files[FILE],
row.names = 1)
## Identifying the Run for this participant
Window_Size <- sub(".*/.*_(WinSize-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9][0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
Run <- sub(".*/.*_(Run-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
ROI <- sub(".*/.*_(ROI-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9].*$") %>%
as.numeric()
## Adding additional information to the dataframe
df_$Window_Size <- Window_Size
df_$Run <- Run
df_$ROI <- ROI
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- rbind(df, df_)
}
}
## Cleaning the space
rm(Run, Window_Size, ROI, files, FILE, df_)
df <- df %>%
select(c("Window_Size", "Run", "ROI", "Model", "term", "estimate",
"std.error", "statistic", "df", "p.value", "ICC_adj",
"ModelComparison", "Base_npar", "Base_AIC", "Base_BIC",
"Base_logLik", "Base_deviance", "Compare_npar", "Compare_AIC",
"Compare_BIC", "Compare_logLik", "Compare_deviance", "Chisq",
"Df", "Pr..Chisq."))
df_ROI <- read.table(paste0(here(), "/Pre-Processing/dir_ROIs/ROIs_Schaefer.txt"))
for (ROI in 1:nrow(df_ROI)){
df$ROI[df$ROI == ROI] <- df_ROI$V1[ROI]
}
df_results_R1 <- df %>%
subset(.$Window_Size == 50 & .$Run == 1 & .$Model == "M4" & .$term == "Value_Cor_Neuro:MidSimSame")
median(df_results_R1$Pr..Chisq.)
df_results_R1$p.value_adj <- p.adjust(df_results_R1$p.value, method = "bonferroni")
df_results_R1_sub <- df_results_R1 %>%
subset(.$p.value_adj < 0.001)
df_results_R2 <- df %>%
subset(.$Window_Size == 50 & .$Run == 2 & .$Model == "M6" & .$term == "Value_Cor_Neuro:EndSimSame")
median(df_results_R2$Pr..Chisq.)
df_results_R2$p.value_adj <- p.adjust(df_results_R2$p.value, method = "bonferroni")
df_results_R2_sub<- df_results_R2 %>%
subset(.$p.value < 0.001)
df_exp <- rbind(df_results_R1_sub,df_results_R2_sub) %>%
select(c("ROI", "estimate", "std.error", "statistic", "df", "p.value_adj")) %>%
group_by(ROI) %>%
summarize(count = n(),
estimate = mean(estimate),
std.error = mean(std.error),
statistic = mean(statistic),
df = mean(df),
p.value_adj = mean(p.value_adj)) %>%
ungroup() %>%
subset(.$count > 1 & .$p.value_adj < 0.001)
df_avg_ROI <- rbind(df_results_R1,df_results_R2) %>%
select(c("ROI", "estimate", "std.error", "statistic", "df", "p.value_adj")) %>%
group_by(ROI) %>%
summarize(count = n(),
estimate = mean(estimate),
std.error = mean(std.error),
statistic = mean(statistic),
df = mean(df),
p.value_adj = mean(p.value_adj)) %>%
ungroup()
P <- df_avg_ROI$p.value_adj
B <- df_avg_ROI$estimate
reticulate::repl_python()
reticulate::repl_python()
