#matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
warnings.simplefilter('ignore')
# matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
# warnings.simplefilter('ignore')
data_dir = '/data/Uncertainty/data/deriv/pipeline_1/fmriprep'
task = "uncertainty"    # Identifying the name of the task at hand
mask = Brain_Data('/data/tools/schaefer_parcellations/MNI/Schaefer2018_400Parcels_Kong2022_17Networks_order_FSLMNI152_2mm.nii.gz')
View(mask)
mask.data()
mask.X()
# matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
# warnings.simplefilter('ignore')
# Defining our directories
data_dir = '/data/Uncertainty/data/deriv/pipeline_1/fmriprep'
# Quick-customize Variables
task = "uncertainty"    # Identifying the name of the task at hand
# Reading in cortical parcellations
mask = Brain_Data('/data/tools/schaefer_parcellations/MNI/Schaefer2018_400Parcels_Kong2022_17Networks_order_FSLMNI152_2mm.nii.gz')
# Splitting the one collection of parcellations into separate binary masks for each region
mask_x = expand_mask(mask)
# Viewing the mask
mask.plot()
plt.show()
# Calling our custom function
source("https://github.com/wj-mitchell/neuRotools/blob/main/ConfoundReducer.R?raw=TRUE")
# Calling the tidyverse package
library(tidyverse)
# Setting our working directory
setwd("/data/Uncertainty/scripts/")
# Noting our participant IDs
PIDs <- read.table("00_batch_subs.txt")[,1] %>%
sprintf("%04d",.)
# Generating onset files for those participants
ConfoundReducer(PIDs = PIDs)
# Calling our custom function
source("https://github.com/wj-mitchell/neuRotools/blob/main/ConfoundReducer.R?raw=TRUE")
# Calling the tidyverse package
library(tidyverse)
# Setting our working directory
setwd("/data/Uncertainty/scripts/")
# Noting our participant IDs
PIDs <- read.table("00_batch_subs.txt")[,1] %>%
sprintf("%04d",.)
# Generating onset files for those participants
ConfoundReducer(PIDs = PIDs)
ConfoundReducer()
View(ConfoundReducer)
dir = "/data/Uncertainty/data/deriv/pipeline_1/fmriprep"
runs = 2
Components = c("Test", "Control")
motion_censor = TRUE
motion_censor_thresh = 0.9
# Check whether this file path is valid.
if (!dir.exists(dir)){
stop(print(paste("Error: The filepath you provided for dir (", dir, ") does not appear to exist. This directory should ideally contain the confound files generated by fMRIPrep for each participant (It should be the level just above individual participant directories). Please respecify your filepath and try again.")))
}
# Check whether runs is entered validly.
if (runs <= 0 | !is.numeric(runs) | is.na(runs)){
stop(print(paste("Error: runs should contain the number of runs your task contains. It must be a numeric value greater than 0. Please respecify the number of runs and try again.")))
}
# Check whether task was entered validly.
if (is.na(Components) | is.null(Components)){
# stop(print(paste("Error: task should be the name heudiconv or your preferred BIDS organizing program assigns to your task. It cannot be left undefined. Please enter something and try again.")))
stop(print(paste("Error: Components should be either 'Control' and/or 'Test'. It cannot be left undefined. Please enter something and try again.")))
}
is.na(Components)
is.na(Components) | is.null(Components)
Components = Components[1]
# Check whether task was entered validly.
if (is.na(Components) | is.null(Components)){
# stop(print(paste("Error: task should be the name heudiconv or your preferred BIDS organizing program assigns to your task. It cannot be left undefined. Please enter something and try again.")))
stop(print(paste("Error: Components should be either 'Control' and/or 'Test'. It cannot be left undefined. Please enter something and try again.")))
}
# Creating a subfunction to make this all smoother
Reducer <- function(file = filename)
{
# Check whether this file exists, and if it doesn't, print an error and give up.
if (!file.exists(file)){
print(paste("Error:", PID, "'s", Run, "file could not be located:", file))
}
# If it does exist . . .
if (file.exists(file)){
# Check if the file is empty
if (file.info(file)$size <= 0){
print(paste("Error:", PID,"'s ", Run,"file does not contain data:", file))
}
# And if the file isn't empty . . .
if (file.info(file)$size > 0){
# Read in the file as a dataframe
df <- read.table(file = file,
sep = '\t',
header = T,
na.strings = c("","NA","n/a"))
# Specifying confounds
confounds = c("a_comp_cor_00","a_comp_cor_01","a_comp_cor_02",
"a_comp_cor_03","a_comp_cor_04","a_comp_cor_05",
names(df)[grep(x = names(df), pattern = "^cosine*")],
names(df)[grep(x = names(df), pattern = "^trans*")],
names(df)[grep(x = names(df), pattern = "^rot*")],
"framewise_displacement", "dvars", "tcompcor")
# Subset the desired columns
df <- subset(df, select = confounds)
# Check if censoring should occur
if (motion_censor == TRUE){
# Tracking how many variables are present
cols <- names(df)
# Iterate through each observation in the dataframe
for (OBS in 2:nrow(df)){
# If that observation isn't an NA
if (!is.na(df$framewise_displacement[OBS])){
# If that observation has a FWD value greater than the threshold ...
if (df$framewise_displacement[OBS] > motion_censor_thresh){
# Create a new column of zeroes
df[,ncol(df) + 1] <- 0
# Add a one for this specific observation in that column
df[OBS, ncol(df)] <- 1
}
}
}
# If any of the observations were greater than out threshold
if (length(which(df$framewise_displacement > motion_censor_thresh)) > 0){
# If we have more than 9 motion outliers
if (length(which(df$framewise_displacement > motion_censor_thresh)) > 09){
# Assigning variable headers
names(df) <- c(cols,
paste0("motion_outlier0", 1:9),
paste0("motion_outlier", 10:length(which(df$framewise_displacement > motion_censor_thresh))))
}
# If we have less than 10 motion outliers
if (length(which(df$framewise_displacement > motion_censor_thresh)) < 10){
# Assigning variable headers
names(df) <- c(cols,
paste0("motion_outlier0", 1:length(which(df$framewise_displacement > motion_censor_thresh))))
}
}
}
}
}
return(df)
}
# Dependencies
library(assertthat)
install.packages("assertthat")
# Dependencies
library(assertthat)
library(dplyr)
library(stringr)
Components = c("Test", "Control")
# Iterating through each of the participants
for (PID in PIDs){
# Iterate through the components
for (COMPONENT in Components){
# If we're looking at a control component
if (COMPONENT == "Control"){
# If the luma file exists
if (file.exists(paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-luma_desc-confounds_timeseries.tsv"))){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-luma_desc-confounds_timeseries.tsv")
# Note what kind of control we have here
control <- "luma"
}
# If the fish file exists
if (file.exists(paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-fish_desc-confounds_timeseries.tsv"))){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-fish_desc-confounds_timeseries.tsv")
# Note what kind of control we have here
control <- "fish"
}
# Run the found reducer subfunction
df <- Reducer(file = filename)
# And then save that dataframe as a new text file within that "look_onsets" folder
write.table(df,
file = paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-", control, "_desc-confounds_timeseries_reduced.tsv"),
sep = "\t",
row.names = FALSE,
col.names = TRUE)
}
# If we're looking at a test component
if (COMPONENT == "Test"){
# Iterate through the runs in the study
for (Run in paste0("run-",1:runs)){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-uncertainty_", Run,"_desc-confounds_timeseries.tsv")
# Run the found reducer subfunction
df <- Reducer(file = filename)
# And then save that dataframe as a new text file within that "look_onsets" folder
write.table(df,
file = paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-uncertainty_", Run,"_desc-confounds_timeseries_reduced.tsv"),
sep = "\t",
row.names = FALSE,
col.names = TRUE)
}
}
}
}
# Iterating through each of the participants
for (PID in PIDs){
# Iterate through the components
for (COMPONENT in Components){
# If we're looking at a control component
if (COMPONENT == "Control"){
# If the luma file exists
if (file.exists(paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-luma_desc-confounds_timeseries.tsv"))){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-luma_desc-confounds_timeseries.tsv")
# Note what kind of control we have here
control <- "luma"
}
# If the fish file exists
if (file.exists(paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-fish_desc-confounds_timeseries.tsv"))){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-fish_desc-confounds_timeseries.tsv")
# Note what kind of control we have here
control <- "fish"
}
# Run the found reducer subfunction
df <- Reducer(file = filename)
# And then save that dataframe as a new text file within that "look_onsets" folder
write.table(df,
file = paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-", control, "_desc-confounds_timeseries_reduced.tsv"),
sep = "\t",
row.names = FALSE,
col.names = TRUE)
}
# If we're looking at a test component
if (COMPONENT == "Test"){
# Iterate through the runs in the study
for (Run in paste0("run-",1:runs)){
# Create a variable to capture the file name for this run
filename <- paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-uncertainty_", Run,"_desc-confounds_timeseries.tsv")
# Run the found reducer subfunction
df <- Reducer(file = filename)
# And then save that dataframe as a new text file within that "look_onsets" folder
write.table(df,
file = paste0(dir, "/sub-", PID, "/func/sub-", PID, "_task-uncertainty_", Run,"_desc-confounds_timeseries_reduced.tsv"),
sep = "\t",
row.names = FALSE,
col.names = TRUE)
}
}
}
}
