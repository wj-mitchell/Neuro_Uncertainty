#matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
warnings.simplefilter('ignore')
# matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
# warnings.simplefilter('ignore')
data_dir = '/data/Uncertainty/data/deriv/pipeline_1/fmriprep'
task = "uncertainty"    # Identifying the name of the task at hand
mask = Brain_Data('/data/tools/schaefer_parcellations/MNI/Schaefer2018_400Parcels_Kong2022_17Networks_order_FSLMNI152_2mm.nii.gz')
View(mask)
mask.data()
mask.X()
# matplotlib inline
import os
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import datetime
from nltools.mask import create_sphere, expand_mask
from nltools.data import Brain_Data, Adjacency
from nltools.stats import align
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from nilearn.plotting import plot_stat_map
import warnings
# warnings.simplefilter('ignore')
# Defining our directories
data_dir = '/data/Uncertainty/data/deriv/pipeline_1/fmriprep'
# Quick-customize Variables
task = "uncertainty"    # Identifying the name of the task at hand
# Reading in cortical parcellations
mask = Brain_Data('/data/tools/schaefer_parcellations/MNI/Schaefer2018_400Parcels_Kong2022_17Networks_order_FSLMNI152_2mm.nii.gz')
# Splitting the one collection of parcellations into separate binary masks for each region
mask_x = expand_mask(mask)
# Viewing the mask
mask.plot()
plt.show()
# Calling our custom function
source("https://github.com/wj-mitchell/neuRotools/blob/main/ConfoundReducer.R?raw=TRUE")
# Calling the tidyverse package
library(tidyverse)
# Setting our working directory
setwd("/data/Uncertainty/scripts/")
# Noting our participant IDs
PIDs <- read.table("00_batch_subs.txt")[,1] %>%
sprintf("%04d",.)
# Generating onset files for those participants
ConfoundReducer(PIDs = PIDs)
