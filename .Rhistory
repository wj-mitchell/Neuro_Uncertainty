}
if (any(r < -0.999)){
r[which(r < -0.999)] <- -0.999
}
return(0.5 * log((1 + r)/(1 - r)))
}
# We have a theory that subjects with more similar hypotheses should demonstrate more similar behavior and neural activity, so we're specifically reading that in
df_qualtrics <- read.csv(paste0(here(), "/Data/df_qualtrics_.csv"),
row.names = 1) %>%
select(c("PID", "TheoryMid", "TheoryEnd"))
# Standardizing the PID so that it matches how it appears in the behavioral data
df_qualtrics$PID <- str_replace(df_qualtrics$PID,pattern = "^SR-", replacement = "sub-")
# Reducing the dimensionality of the theories column
df_qualtrics$TheoryMid[df_qualtrics$TheoryMid != "Jonathan Fraser"] <- "Not Jonathan Fraser"
df_qualtrics$TheoryEnd[df_qualtrics$TheoryEnd != "Jonathan Fraser"] <- "Not Jonathan Fraser"
plots_list <- list()
## Iterating through each of these files
for (ROI in examples){
for (RUN in 1:2){
# Reading in the behavioral data for this specific window size and run
df_behav <- read.csv(paste0(here(),
"/Data/Sliding_Window/Type-Behav_WinSize-50_Run-",
RUN,".csv"),
row.names = 1)
# Standardizing the PID information to match how it appears in the neuro file
df_behav$PID1 <- df_behav$PID1 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
df_behav$PID2 <- df_behav$PID2 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
# Merging the behavioral data with the qualtrics data for both PID1 and PID2
df_behav <- merge(df_behav,
df_qualtrics,
by.x = "PID1",
by.y = "PID",
all.x = T) %>%
merge(.,
df_qualtrics,
by.x = "PID2",
by.y = "PID",
all.x = T,suffixes = c("_PID1", "_PID2"))
# Creating a new column to track whether participants had the same theory or different theories at the mid point
df_behav$MidSim <- NA
df_behav$MidSim[df_behav$TheoryMid_PID1 == df_behav$TheoryMid_PID2] <- "Same"
df_behav$MidSim[df_behav$TheoryMid_PID1 != df_behav$TheoryMid_PID2] <- "Different"
# Creating a new column to track whether participants had the same theory or different theories at the end point
df_behav$EndSim <- NA
df_behav$EndSim[df_behav$TheoryEnd_PID1 == df_behav$TheoryEnd_PID2] <- "Same"
df_behav$EndSim[df_behav$TheoryEnd_PID1 != df_behav$TheoryEnd_PID2] <- "Different"
# Reducing the columns that we're going to carry forward to the neuro data merger
df_behav <- df_behav %>%
select(c("PID1", "PID2", "Run", "Window", "Value_Cor_Behav", "MidSim", "EndSim"))
# Applying a Fisher's Z Transform to the Correlation Data
df_behav$Value_Cor_Behav_fz <- fishers_z(df_behav$Value_Cor_Behav)
# Reading in the data relevant to this window, run, and ROI
df_neuro <- read.csv(paste0(here(),
"/Data/Sliding_Window/nROI-400_WinSize-50_Run-",RUN,"_ROI-", ROI,".csv"),
row.names = 1)
# Applying a Fisher's Z Transform to the Correlation Data
df_neuro$Value_Cor_Neuro_fz <- fishers_z(df_neuro$Value_Cor_Neuro)
# Merging out behavioral and neural data together
df_ <- merge(x = df_behav,
y = df_neuro)
## If this is the first file
if (RUN == 1){
# M4 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * MidSim + Window + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = MidSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
## If it's a later file
if (RUN > 1){
# M6 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * EndSim + Window + MidSim + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = EndSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
plot_list <- list(plot_list, Plot)
}
}
## Loading Packages
pacman::p_load(here,
tidyverse)
examples <- c(58, 80, 109, 130, 161, 192, 197, 209, 247, 349)
fishers_z <- function(r) {
if (any(r > 0.999)){
r[which(r > 0.999)] <- 0.999
}
if (any(r < -0.999)){
r[which(r < -0.999)] <- -0.999
}
return(0.5 * log((1 + r)/(1 - r)))
}
# We have a theory that subjects with more similar hypotheses should demonstrate more similar behavior and neural activity, so we're specifically reading that in
df_qualtrics <- read.csv(paste0(here(), "/Data/df_qualtrics_.csv"),
row.names = 1) %>%
select(c("PID", "TheoryMid", "TheoryEnd"))
# Standardizing the PID so that it matches how it appears in the behavioral data
df_qualtrics$PID <- str_replace(df_qualtrics$PID,pattern = "^SR-", replacement = "sub-")
# Reducing the dimensionality of the theories column
df_qualtrics$TheoryMid[df_qualtrics$TheoryMid != "Jonathan Fraser"] <- "Not Jonathan Fraser"
df_qualtrics$TheoryEnd[df_qualtrics$TheoryEnd != "Jonathan Fraser"] <- "Not Jonathan Fraser"
plots_list <- list()
## Iterating through each of these files
for (ROI in examples){
for (RUN in 1:2){
# Reading in the behavioral data for this specific window size and run
df_behav <- read.csv(paste0(here(),
"/Data/Sliding_Window/Type-Behav_WinSize-50_Run-",
RUN,".csv"),
row.names = 1)
# Standardizing the PID information to match how it appears in the neuro file
df_behav$PID1 <- df_behav$PID1 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
df_behav$PID2 <- df_behav$PID2 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
# Merging the behavioral data with the qualtrics data for both PID1 and PID2
df_behav <- merge(df_behav,
df_qualtrics,
by.x = "PID1",
by.y = "PID",
all.x = T) %>%
merge(.,
df_qualtrics,
by.x = "PID2",
by.y = "PID",
all.x = T,suffixes = c("_PID1", "_PID2"))
# Creating a new column to track whether participants had the same theory or different theories at the mid point
df_behav$MidSim <- NA
df_behav$MidSim[df_behav$TheoryMid_PID1 == df_behav$TheoryMid_PID2] <- "Same"
df_behav$MidSim[df_behav$TheoryMid_PID1 != df_behav$TheoryMid_PID2] <- "Different"
# Creating a new column to track whether participants had the same theory or different theories at the end point
df_behav$EndSim <- NA
df_behav$EndSim[df_behav$TheoryEnd_PID1 == df_behav$TheoryEnd_PID2] <- "Same"
df_behav$EndSim[df_behav$TheoryEnd_PID1 != df_behav$TheoryEnd_PID2] <- "Different"
# Reducing the columns that we're going to carry forward to the neuro data merger
df_behav <- df_behav %>%
select(c("PID1", "PID2", "Run", "Window", "Value_Cor_Behav", "MidSim", "EndSim"))
# Applying a Fisher's Z Transform to the Correlation Data
df_behav$Value_Cor_Behav_fz <- fishers_z(df_behav$Value_Cor_Behav)
# Reading in the data relevant to this window, run, and ROI
df_neuro <- read.csv(paste0(here(),
"/Data/Sliding_Window/nROI-400_WinSize-50_Run-",RUN,"_ROI-", ROI,".csv"),
row.names = 1)
# Applying a Fisher's Z Transform to the Correlation Data
df_neuro$Value_Cor_Neuro_fz <- fishers_z(df_neuro$Value_Cor_Neuro)
# Merging out behavioral and neural data together
df_ <- merge(x = df_behav,
y = df_neuro)
## If this is the first file
if (RUN == 1){
# M4 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * MidSim + Window + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = MidSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
## If it's a later file
if (RUN > 1){
# M6 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * EndSim + Window + MidSim + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = EndSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
plots_list <- list(plots_list, Plot)
}
}
# ## Cleaning the space
# rm(ROI, RUN, examples, fishers_z)
View(plots_list)
length(plots_list)
plots_list[[1]]
plots_list[[1]][1]
## Loading Packages
pacman::p_load(here,
tidyverse)
examples <- c(58, 80, 109, 130, 161, 192, 197, 209, 247, 349)
fishers_z <- function(r) {
if (any(r > 0.999)){
r[which(r > 0.999)] <- 0.999
}
if (any(r < -0.999)){
r[which(r < -0.999)] <- -0.999
}
return(0.5 * log((1 + r)/(1 - r)))
}
# We have a theory that subjects with more similar hypotheses should demonstrate more similar behavior and neural activity, so we're specifically reading that in
df_qualtrics <- read.csv(paste0(here(), "/Data/df_qualtrics_.csv"),
row.names = 1) %>%
select(c("PID", "TheoryMid", "TheoryEnd"))
# Standardizing the PID so that it matches how it appears in the behavioral data
df_qualtrics$PID <- str_replace(df_qualtrics$PID,pattern = "^SR-", replacement = "sub-")
# Reducing the dimensionality of the theories column
df_qualtrics$TheoryMid[df_qualtrics$TheoryMid != "Jonathan Fraser"] <- "Not Jonathan Fraser"
df_qualtrics$TheoryEnd[df_qualtrics$TheoryEnd != "Jonathan Fraser"] <- "Not Jonathan Fraser"
plots_list <- list()
## Iterating through each of these files
for (ROI in examples){
for (RUN in 1:2){
# Reading in the behavioral data for this specific window size and run
df_behav <- read.csv(paste0(here(),
"/Data/Sliding_Window/Type-Behav_WinSize-50_Run-",
RUN,".csv"),
row.names = 1)
# Standardizing the PID information to match how it appears in the neuro file
df_behav$PID1 <- df_behav$PID1 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
df_behav$PID2 <- df_behav$PID2 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
# Merging the behavioral data with the qualtrics data for both PID1 and PID2
df_behav <- merge(df_behav,
df_qualtrics,
by.x = "PID1",
by.y = "PID",
all.x = T) %>%
merge(.,
df_qualtrics,
by.x = "PID2",
by.y = "PID",
all.x = T,suffixes = c("_PID1", "_PID2"))
# Creating a new column to track whether participants had the same theory or different theories at the mid point
df_behav$MidSim <- NA
df_behav$MidSim[df_behav$TheoryMid_PID1 == df_behav$TheoryMid_PID2] <- "Same"
df_behav$MidSim[df_behav$TheoryMid_PID1 != df_behav$TheoryMid_PID2] <- "Different"
# Creating a new column to track whether participants had the same theory or different theories at the end point
df_behav$EndSim <- NA
df_behav$EndSim[df_behav$TheoryEnd_PID1 == df_behav$TheoryEnd_PID2] <- "Same"
df_behav$EndSim[df_behav$TheoryEnd_PID1 != df_behav$TheoryEnd_PID2] <- "Different"
# Reducing the columns that we're going to carry forward to the neuro data merger
df_behav <- df_behav %>%
select(c("PID1", "PID2", "Run", "Window", "Value_Cor_Behav", "MidSim", "EndSim"))
# Applying a Fisher's Z Transform to the Correlation Data
df_behav$Value_Cor_Behav_fz <- fishers_z(df_behav$Value_Cor_Behav)
# Reading in the data relevant to this window, run, and ROI
df_neuro <- read.csv(paste0(here(),
"/Data/Sliding_Window/nROI-400_WinSize-50_Run-",RUN,"_ROI-", ROI,".csv"),
row.names = 1)
# Applying a Fisher's Z Transform to the Correlation Data
df_neuro$Value_Cor_Neuro_fz <- fishers_z(df_neuro$Value_Cor_Neuro)
# Merging out behavioral and neural data together
df_ <- merge(x = df_behav,
y = df_neuro)
## If this is the first file
if (RUN == 1){
# M4 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * MidSim + Window + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = MidSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
## If it's a later file
if (RUN > 1){
# M6 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * EndSim + Window + MidSim + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = EndSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(-1,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
tiff(paste0(here(), "/Plots/nROI-400_WinSize-50_Run-", RUN, "_ROI-", ROI,"_plot.tiff"),
res = 300,
units = "in",
width = 12,
height = 9)
print(Plot)
dev.off()
}
}
# ## Cleaning the space
# rm(ROI, RUN, examples, fishers_z)
for (PLOT in 1:length(plots_list)){
}
## Loading Packages
pacman::p_load(here,
tidyverse)
examples <- c(58, 80, 109, 130, 161, 192, 197, 209, 247, 349)
fishers_z <- function(r) {
if (any(r > 0.999)){
r[which(r > 0.999)] <- 0.999
}
if (any(r < -0.999)){
r[which(r < -0.999)] <- -0.999
}
return(0.5 * log((1 + r)/(1 - r)))
}
# We have a theory that subjects with more similar hypotheses should demonstrate more similar behavior and neural activity, so we're specifically reading that in
df_qualtrics <- read.csv(paste0(here(), "/Data/df_qualtrics_.csv"),
row.names = 1) %>%
select(c("PID", "TheoryMid", "TheoryEnd"))
# Standardizing the PID so that it matches how it appears in the behavioral data
df_qualtrics$PID <- str_replace(df_qualtrics$PID,pattern = "^SR-", replacement = "sub-")
# Reducing the dimensionality of the theories column
df_qualtrics$TheoryMid[df_qualtrics$TheoryMid != "Jonathan Fraser"] <- "Not Jonathan Fraser"
df_qualtrics$TheoryEnd[df_qualtrics$TheoryEnd != "Jonathan Fraser"] <- "Not Jonathan Fraser"
## Iterating through each of these files
for (ROI in examples){
for (RUN in 1:2){
# Reading in the behavioral data for this specific window size and run
df_behav <- read.csv(paste0(here(),
"/Data/Sliding_Window/Type-Behav_WinSize-50_Run-",
RUN,".csv"),
row.names = 1)
# Standardizing the PID information to match how it appears in the neuro file
df_behav$PID1 <- df_behav$PID1 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
df_behav$PID2 <- df_behav$PID2 %>%
str_replace(pattern = "_.$", replacement = "") %>%
str_extract(pattern = "sub-....")
# Merging the behavioral data with the qualtrics data for both PID1 and PID2
df_behav <- merge(df_behav,
df_qualtrics,
by.x = "PID1",
by.y = "PID",
all.x = T) %>%
merge(.,
df_qualtrics,
by.x = "PID2",
by.y = "PID",
all.x = T,suffixes = c("_PID1", "_PID2"))
# Creating a new column to track whether participants had the same theory or different theories at the mid point
df_behav$MidSim <- NA
df_behav$MidSim[df_behav$TheoryMid_PID1 == df_behav$TheoryMid_PID2] <- "Same"
df_behav$MidSim[df_behav$TheoryMid_PID1 != df_behav$TheoryMid_PID2] <- "Different"
# Creating a new column to track whether participants had the same theory or different theories at the end point
df_behav$EndSim <- NA
df_behav$EndSim[df_behav$TheoryEnd_PID1 == df_behav$TheoryEnd_PID2] <- "Same"
df_behav$EndSim[df_behav$TheoryEnd_PID1 != df_behav$TheoryEnd_PID2] <- "Different"
# Reducing the columns that we're going to carry forward to the neuro data merger
df_behav <- df_behav %>%
select(c("PID1", "PID2", "Run", "Window", "Value_Cor_Behav", "MidSim", "EndSim"))
# Applying a Fisher's Z Transform to the Correlation Data
df_behav$Value_Cor_Behav_fz <- fishers_z(df_behav$Value_Cor_Behav)
# Reading in the data relevant to this window, run, and ROI
df_neuro <- read.csv(paste0(here(),
"/Data/Sliding_Window/nROI-400_WinSize-50_Run-",RUN,"_ROI-", ROI,".csv"),
row.names = 1)
# Applying a Fisher's Z Transform to the Correlation Data
df_neuro$Value_Cor_Neuro_fz <- fishers_z(df_neuro$Value_Cor_Neuro)
# Merging out behavioral and neural data together
df_ <- merge(x = df_behav,
y = df_neuro)
## If this is the first file
if (RUN == 1){
# M4 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * MidSim + Window + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = MidSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(0,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
## If it's a later file
if (RUN > 1){
# M6 <- lmer(Value_Cor_Behav ~ Value_Cor_Neuro * EndSim + Window + MidSim + (1 | PID1) + (1 | PID2), data = df, REML = F)
Plot <- ggplot(data = df_, aes(x = Value_Cor_Neuro, y = Value_Cor_Behav, color = EndSim)) +
stat_smooth(method = "lm", linewidth = 3) +
scale_color_discrete("Theory Similarity") +
labs(x = "Neural Similarity",
y ="Behavioral Similarity") +
coord_cartesian(x = c(-1,1), y = c(0,1)) +
theme_classic() +
theme(axis.title = element_text(size = 32, color = "Black")) +
theme(axis.text.x = element_text(size = 36, color = "Black")) +
theme(axis.text.y = element_text(size = 30, color = "Black"))
}
tiff(paste0(here(), "/Plots/nROI-400_WinSize-50_Run-", RUN, "_ROI-", ROI,"_plot.tiff"),
res = 300,
units = "in",
width = 12,
height = 9)
print(Plot)
dev.off()
}
}
# ## Cleaning the space
# rm(ROI, RUN, examples, fishers_z)
## Loading Packages
pacman::p_load(here,
tidyverse)
files <- list.files(paste0(here(), "/Data/Sliding_Window/Results"),
full.names = TRUE)
## Iterating through each of these files
for (FILE in 1:length(files)){
## Reading in the data for this iteration
df_ <- read.csv(files[FILE],
row.names = 1)
## Identifying the Run for this participant
Window_Size <- sub(".*/.*_(WinSize-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9][0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
Run <- sub(".*/.*_(Run-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9]$") %>%
as.numeric()
## Identifying the Run for this participant
ROI <- sub(".*/.*_(ROI-\\d+)_.*", "\\1", files[FILE]) %>%
str_extract("[0-9].*$") %>%
as.numeric()
## Adding additional information to the dataframe
df_$Window_Size <- Window_Size
df_$Run <- Run
df_$ROI <- ROI
## If this is the first file
if (FILE == 1){
## Make it the standard
df <- df_
}
## If it's a later file
if (FILE > 1){
## Bind the columns together
df <- rbind(df, df_)
}
}
## Cleaning the space
rm(Run, Window_Size, ROI, files, FILE, df_)
df <- df %>%
select(c("Window_Size", "Run", "ROI", "Model", "term", "estimate",
"std.error", "statistic", "df", "p.value", "ICC_adj",
"ModelComparison", "Base_npar", "Base_AIC", "Base_BIC",
"Base_logLik", "Base_deviance", "Compare_npar", "Compare_AIC",
"Compare_BIC", "Compare_logLik", "Compare_deviance", "Chisq",
"Df", "Pr..Chisq."))
df_ROI <- read.table(paste0(here(), "/Pre-Processing/dir_ROIs/ROIs_Schaefer.txt"))
df$ROI_cat <- NA
for (ROI in 1:nrow(df_ROI)){
df$ROI_cat[df$ROI == ROI] <- df_ROI$V1[ROI]
}
df_results_R1 <- df %>%
subset(.$Window_Size == 50 & .$Run == 1 & .$Model == "M4" & .$term == "Value_Cor_Neuro:MidSimSame")
median(df_results_R1$Pr..Chisq.)
df_results_R1$p.value_adj <- p.adjust(df_results_R1$p.value, method = "bonferroni")
df_results_R1_sub <- df_results_R1 %>%
subset(.$p.value_adj < 0.001)
df_results_R2 <- df %>%
subset(.$Window_Size == 50 & .$Run == 2 & .$Model == "M6" & .$term == "Value_Cor_Neuro:EndSimSame")
median(df_results_R2$Pr..Chisq.)
df_results_R2$p.value_adj <- p.adjust(df_results_R2$p.value, method = "bonferroni")
df_results_R2_sub<- df_results_R2 %>%
subset(.$p.value < 0.001)
df_exp <- rbind(df_results_R1_sub,df_results_R2_sub) %>%
select(c("ROI", "ROI_cat", "estimate", "std.error", "statistic", "df", "p.value_adj")) %>%
group_by(ROI) %>%
summarize(count = n(),
estimate = mean(estimate),
std.error = mean(std.error),
statistic = mean(statistic),
df = mean(df),
p.value_adj = mean(p.value_adj)) %>%
ungroup() %>%
subset(.$count > 1 & .$p.value_adj < 0.001)
df_avg_ROI <- rbind(df_results_R1,df_results_R2) %>%
select(c("ROI", "ROI_cat", "estimate", "std.error", "statistic", "df", "p.value_adj")) %>%
group_by(ROI) %>%
summarize(ROI_cat = ROI_cat[1],
count = n(),
estimate = mean(estimate),
std.error = mean(std.error),
statistic = mean(statistic),
df = mean(df),
p.value_adj = mean(p.value_adj)) %>%
ungroup()
write.csv(df_avg_ROI, paste0(here(), "/Data/Sliding_Window/df_avg_resultsROI.csv"))
View(df_avg_ROI)
write.csv(df_avg_ROI[c(58,80,109,130,161,192,197,209,247,349),], "/data/Uncertainty/TEMP.csv")
